<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Matei Gabriel Cosa</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="/assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<!-- Header -->
								<header id="header">
									<ul class="icons" style="font-size: 1.5em;">
										<li><a href="https://github.com/MateiCosa" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
										<li><a href="https://www.linkedin.com/in/mateicosa/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
										<li><a href="mailto: mateigabriel.cosa@studbocconi.it" class="icon fa-envelope"><span class="label"></span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Can We Trust Statistics & Algorithms? <br> A talk by prof. David Spiegelhalter OBE</h1>
									</header>

									<span class="image main"><img src="/images/davids_2.jpeg" alt="" /></span>

									<p>Prof. David Spiegelhalter OBE is one of those remarkable personalities that bridge the gap between academia and the general public, thereby bringing scientific thinking into everyday life. His talk at SDA Bocconi was an insightful presentation of how data can be used and most often misused by journalists, researchers and politicians.</p>
									<p>With the recent times being dominated by a global pandemic, the rise of fake news, and ground-breaking advances in the field of AI, taking a responsible approach to science and communication becomes vital. Building credibility is essential for complying with ethical standards. This requires being open about data and where they come from, as well as the algorithms used to process them and the potential risks and limitations that arise from them. </p>
									<p>An additional complication that people in academia and the industry must face is the so-called "explainability crisis". This phenomenon is the result of increasing the scale and complexity of machine learning models that are able to accomplish extraordinary feats of performance, while acting like a black-box. Particulay problematic is the use of such tools for automated decison-making in situations that may have dramatic impact on the society, such as law enforcement.</p>

									<hr class="major" />

									<h2>Trust vs Trustworthiness</h2>

									<span class="image main"><img src="/images/davids_3.jpeg" alt="" /></span>

									<p>From rather harmless spurious correlations, to potentially dangerous claims about vaccines during the COVID-19 pandemic, telling a story with data requires great responsibility. It is precisely the concept of accountability that prof. Spiegelhalter highlighted in his lecture. Being trusted is not the same as being trustworthy, since trust is rather subjective, whereas trustworthiness requires a set of principles such as being open about the limitations of your analysis, uncertainty quantification and the potential biases in the underlying data. </p>
									<p>Another aspect to keeep in mind is the audience to which you are communicating. Discussing technical aspects of a statistical analysis may be appropriate in an academic context, but not when addressing the general public. This particular challenge is something that prof. Spiegelhalter tackled during the COVID-19 pandemic, when he and his colleagues attempted to educate audiences of major news outlets on reading statistical data about vaccines, mortality rates, and the spread of the disease. </p>
									<p>A particulary relevant moment that prof. Spiegelhalter shared during his lecture was a show on the BBC where a graph that he worked on was presented. The diagram about vaccine efficiency and risks for different age groups overwhelmingly supported getting a dose for everyone, except for healthy teenagers and young adults. This contradicted official statements of the British government, as well as vacine advocates, but was something that had to be communicated, claimed the Cambridge professor, since it allows people to view the full picture and understand the entire story told by the data.</p>

									<hr class="major" />

									<h2>Explainability</h2>
									<p>Being trustworthy has become more and more difficult due to the development of larger and more complex deep learning models. Training models with billions of parameters on mind-boggling amounts of data results in impressive performance. This, however, comes at a cost. While most people may understand the coefficients in a linear regression, attempting to grasp what the hundreds of billions of parameters in a model such as GPT-4 is simply futile.</p>
									<p>When large language models (LLM's) confidently spit out non-sense without warning, it is hard to get the general public to trust in AI. Lacking a clear explanation or references to trusted sources leaves people unable to wrap their minds around how such a machine "thinks". This may seem less important when talking to a chatbot that fails at basic algebra and common sense, but it is crucial if AI is used to decide whether to hire someone or to give out a loan. It is evident that applications of AI for decision-making in sensitive areas should be carefully analyzed.</p>

									<hr class="major" />

									<h2>Thoughts about the future</h2>

									<span class="image main"><img src="/images/davids_1.jpeg" alt="" /></span>

									<p>While innovation will continue to take place at an impressive pace, it is important to educate people in understanding both the advantages, as well as the risks that come with it. Fortunately, this is something that people like prof. Spiegelhalter have set out to accomplish.</p>
									<p>Striving to be trustworthy is a complex challenge that requires a blend of scientific discovery to allow a deeper understanding of our models and honest communication to highlight the advantages and limitations of our approach. By combining the two, one may hope to achieve an ethical and transparent development of AI that is both efficient and explainable to some extent. This should be our goal moving forward.</p>
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="/index.html">Home</a></li>
										<li><a href="/pages/blog.html">Blog</a></li>
										<li><a href="/pages/projects.html">Projects</a></li>
										<li><a href="/#about">About</a></li>
									</ul>
								</nav>

							<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<p>Interested in a project collaboration, looking for a passionate and hard-working intern or simply wish to share some interesting information? Feel free to contact me at:</p>
								<ul class="contact">
									<li class="icon solid fa-envelope"><a href="mailto:mateigabriel.cosa@studbocconi.it">mateigabriel.cosa@studbocconi.it</a></li>
								</ul>
							</section>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy; Matei Gabriel Cosa. <br> Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="/assets/js/jquery.min.js"></script>
			<script src="/assets/js/browser.min.js"></script>
			<script src="/assets/js/breakpoints.min.js"></script>
			<script src="/assets/js/util.js"></script>
			<script src="/assets/js/main.js"></script>

	</body>
</html>